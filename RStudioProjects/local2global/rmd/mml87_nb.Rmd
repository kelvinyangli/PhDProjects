---
title: "mml87_nb"
author: "Kelvin"
date: "27 June 2017"
output:
  html_document: default
  pdf_document: default
---

```{r global_options, include=F, warning=F, message=F, eval=F, echo=F, message=F}
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE, echo = T, eval = T)
if (.Platform$OS.type == "windows") {
  dir = "C:/Users/"
} else {
  dir = "/home/"
}
source(paste0(dir, "kl/Documents/PhDProjects/RStudioProjects/local2global/scripts/load_libraries.R"))
```

## Random model
```{r, eval=T}
nXs = 1
dag = empty.graph(c("Y", paste0("X", 1:nXs)))
for (i in 2:nnodes(dag)) {
  dag = set.arc(dag, nodes(dag)[1], nodes(dag)[i])
}
#dag = randDag(10, 2)
#graphviz.plot(dag)
cpts = randCPTs(dag, 2, 1)
sampleSize = n = 10000
data = rbn(cpts, n)
vars = colnames(data)
arities = sapply(data, nlevels)
names(arities) = c()
y = "Y"
#x = bnlearn::mb(dag, y)
yIndex = which(vars == y)
#xIndices = which(vars %in% x)
#mb(dag, y)
cpts
```

## Executing MML_NB
```{r, eval = T}
#for (i in 2:length(vars)) {
  i = 2:nnodes(dag)
  indices = c(i)
  pars = mle_nb(data, vars, indices, yIndex, 0.5)
  probSign = get_prob_sign(data)
  (i_nb = mml_nb(data, probSign, vars, arities, sampleSize, x=vars[indices], y, debug = TRUE))
  #forward_greedy(data, arities, vars, sampleSize, y, score = mml_nb, probSign = probSign, debug = T)
#}

```
## MML_Logit

```{r}
dataNumeric = factor2numeric(data)
vars = names(data)
sampleSize = n
(i_lr = mml_logit(data, arities, sampleSize, vars[indices], y, sigma = 3, debug = T))
#forward_greedy(data, arities, vars, sampleSize, y, score = mml_logit, dataNumeric = dataNumeric, debug = F)
```

## MML_CPT
```{r}
indexListPerNodePerValue = count_occurance(data, arities)
#forward_greedy_fast(data, indexListPerNodePerValue, arities, sampleSize, y, base = exp(1), debug = F)
(i_cpt = mml_cpt(indexListPerNodePerValue, arities, sampleSize, indices, yIndex, base = exp(1)))
dagCPT = empty.graph(c(y, vars[indices]))
for (i in 2:nnodes(dagCPT)) {
  dagCPT = set.arc(dagCPT, nodes(dagCPT)[i], nodes(dagCPT)[1])
}
cptsEst = bn.fit(dagCPT, data[, c(yIndex, indices)], method = "bayes")
ss = 0 
for (i in 1:nrow(data)) {
  valueIndices = as.numeric(data[i, c(yIndex, indices)])
  ss = ss + log(do.call("[", c(list(cptsEst[[1]]$prob), as.list(valueIndices))))
}
cat("@ 1st part:", i_cpt + ss, "\n")
cat("@ 2nd part:", -ss, "\n")
```
The above mml + cpt is even smaller than mml + nb, which is expected to be shorter due to less number of parameters comparing with a full cpt!!!

## Comparison
```{r, eval = F}
i_nb
i_cpt
i_lr
```

## Observations
* In mml_nb, det(fim) are sometimes small negative value, not sure what's the problem. In addition, sometimes det(fim) is very small positive value, hence log(det(fim)) is a large negative value, which makes the first part of mml_nb negative, this is not right!

* singular matrix, columns are not linearly independent

* try: change values of parameters to see how sensitive the log likelihood is 

* try: plot the log likelihood to see its shape 




