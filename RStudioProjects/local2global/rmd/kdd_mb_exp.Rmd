---
title: "kdd_mb_exp"
author: "kl"
date: "31 January 2018"
output: html_document
---

```{r global_options, include=F, warning=F, eval=F, echo=F, message=F}
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE, echo = F, eval = T)
if (.Platform$OS.type == "windows") {
  dir = "C:/Users/"
} else {
  dir = "/home/"
}
source(paste0(dir, "kl/Documents/PhDProjects/RStudioProjects/local2global/scripts/load_libraries.R"))

```

These exp take 5 parameters into account, ordered by priority: 

* nvars 10, 30, 50, 100
* n 50, 500, 5000
* npa 2, 4, 6
* narity 2, 3, 4
* beta (derichlet concentration parameter) 1, 5, 25

```{r}
dir = "~/Documents/Experiments/kdd_exp/"
vnvars = c(10, 50, 100)
vnpa = c(2, 4, 6)
vnarity = c(2, 3, 4)
vbeta = c(1, 5, 25)
vn = c(50, 500, 5000)
for (nvars in vnvars) {
  
  for (npa in vnpa) {
          
    for (narity in vnarity) {
      
      for (beta in vbeta) {
        nvars = 50
        npa = narity = 2 
        beta = 1
        dirname = paste(nvars, npa, narity, beta, sep = "_")
        
        for (itr in 1:5) {
  
          sd = randSeed()
          set.seed(sd)
          dag = randDag(nvars, npa)
          cpts = randCPTs(dag, narity, beta)
          nodes = bnlearn::nodes(dag)
          mbtrue = list()
          i = 1
          for (x in nodes) {
            mbtrue[[i]] = bnlearn::mb(dag, x)
            i = i + 1
          }
          saveRDS(dag, paste0(dir, dirname, "/dag/dag_", sd, ".rds"))
          saveRDS(cpts, paste0(dir, dirname, "/cpts/cpt_", sd, ".rds"))
          saveRDS(mbtrue, paste0(dir, dirname, "/mb_true/mb_", sd, ".rds"))
          
          for (n in vn) {
            
            datasd = randSeed()
            set.seed(datasd)
            data = rbn(cpts, n)  
            saveRDS(data, paste0(dir, dirname, "/data_rds/data_", n, "_", sd, "_", datasd, ".rds"))
            write.csv(data, paste0(dir, dirname, "/data_csv/data_", n, "_", sd, "_", datasd, ".csv"), row.names = F)
            
          }
        }# end itr
      }# end beta
    }
  }
}

```


## learning
```{r}
# library(parallel)
# library(foreach)
# library(doParallel)
dir = "~/Documents/Experiments/kdd_exp/"
params = "30_5_4_1"
datasets = list.files(paste0(dir, params, "/data_rds/"))
#dags = list.files(paste0(dir, params, "/dag/"))
for (i in 36:50) {
  cat(i, "\n")
  data = readRDS(paste0(dir, params, "/data_rds/", datasets[i]))
  #dag = readRDS(paste0(dir, params, "/dag/", dags[i]))
  filename = paste0(strsplit(datasets[i], "_")[[1]][-1], collapse = "_")
  nvars = ncol(data)
  vars = names(data)
  n = nrow(data)
  arities = sapply(data, nlevels)
  names(arities) = c()
  varCnt = count_occurance(data, arities)
  mbcpt = mbnb = mbrand = list()
  
  mbiamb = lapply(vars, learn.mb, x = data, method = "iamb")
  saveRDS(mbiamb, paste0(dir, params, "/iamb/iamb_", filename))
  # mbinter = lapply(vars, learn.mb, x = data, method = "inter.iamb")
  # saveRDS(mbinter, paste0(dir, params, "/inter_iamb/inter_", filename))
  # 
  data = data.matrix(data)
  
  # for (target in vars) {
  #   cat(target, "\n")
  #   forward_greedy(data, arities, vars, n, target, "random", varCnt = varCnt, prior = "uniform")
  # }
  
  ## starting parallel computing ###
  no_cores = 3
  registerDoParallel(no_cores)

  mbrand = foreach(target = vars,
      .combine = list,
      .multicombine = TRUE) %dopar%
    forward_greedy(data, arities, vars, n, target, "random", varCnt = varCnt, prior = "uniform")

  mbcpt = foreach(target = vars,
      .combine = list,
      .multicombine = TRUE) %dopar%
    forward_greedy_fast(data, varCnt, arities, vars, n, target)

  mbnb = foreach(target = vars,
      .combine = list,
      .multicombine = TRUE) %dopar%
    forward_greedy(data, arities, vars, n, target, "nb")

  saveRDS(mbrand, paste0(dir, params, "/rand/rand_", filename))
  saveRDS(mbcpt, paste0(dir, params, "/cpt/cpt_", filename))
  saveRDS(mbnb, paste0(dir, params, "/nb/nb_", filename))
  
}

stopImplicitCluster()
```

## Sym enforcement using mml
```{r}
m = matrix(0, 10, 3)
for (k in 1:10) {
dag = randDag(10, 3)
cpts = randCPTs(dag, 4, 1)
data = rbn(cpts, 500)
vars = names(data)
n = nrow(data)
arities = sapply(data, nlevels)
names(arities) = c()
varCnt = count_occurance(data, arities)
data = data.matrix(data)
mbt = lapply(vars, bnlearn::mb, x = dag)
mbl = lapply(vars, forward_greedy_fast, data = data, varCnt = varCnt, arities = arities, vars = vars, sampleSize = n)
mbDiscrepancy = mb_discrepancy(vars, mbl)
if (nrow(mbDiscrepancy) > 0) {
  # cat("dis exist! \n")
  mbl_sym = sym_enforcement_mml(vars, varCnt, arities, n, mbl, mbDiscrepancy)
  mbl_sym2 = symmetry_correction(vars, mbl, "AND")
  #mb_discrepancy(vars, mbl_sym)
  ed = ed_sym = ed_sym2 = c()
  for (i in 1:ncol(data)) {
    ed = c(ed, mb_false_finding(mbt[[i]], mbl[[i]]))
    ed_sym = c(ed_sym, mb_false_finding(mbt[[i]], mbl_sym[[i]]))
    ed_sym2 = c(ed_sym2, mb_false_finding(mbt[[i]], mbl_sym2[[i]]))
  }
  # cat(mean(ed), "\n")
  # cat(mean(ed_sym), "\n")
  # cat(mean(ed_sym2), "\n")
}
m[k, ] = c(mean(ed), mean(ed_sym), mean(ed_sym2))
}

```

## sym enforcement using deterministic AND rule
```{r}


```

## Evaluating
```{r}
dir = "~/Documents/Experiments/kdd_exp/"
model = "50_5_4_1"
true = list.files(paste0(dir, model, "/mb_true"))
dags = list.files(paste0(dir, model, "/dag"))
#dag = readRDS(paste0(dir, model, "/dag/", dags[1]))

m = matrix(0, 3, 11)
m[, 1] = model
amb = c() # average mb size
for (x in true) {
  
  mbt = readRDS(paste0(dir, model, "/mb_true/", x))
  amb = c(amb, round(sum(sapply(mbt, length)) / length(mbt), 1))
  
}
m[, 2] = mean(amb)
m[, 3] = c(500, 2000, 5000) 
l = 4

for (folder in c("cpt_const_dif", "nb", "rand", "iamb")) {
  
  for (n in c(500, 2000, 5000)) {

    if (n == 2000) {
      ind = 2
    } else if (n == 5000) {
      ind = 3
    } else if (n == 500) {
      ind = 1
    }
       
    learned = list.files(paste0(dir, model, "/", folder), pattern = paste0("_", n, "_"))
    datasets = list.files(paste0(dir, model, "/data_rds"), pattern = paste0("_", n, "_"))
    edList = rep(list(rep(0, length(mbt))), length(learned)) # edit distance
    retList = rep(list(c()), length(learned)) # precision and recall
    for (i in 1:length(true)) {
      
      mbt = readRDS(paste0(dir, model, "/mb_true/", true[i]))
      for (j in ((5 * (i - 1)) + 1):(5 * i)) {
        
        data = readRDS(paste0(dir, model, "/data_rds/", datasets[j]))
        mbl = readRDS(paste0(dir, model, "/", folder, "/", learned[j]))
        
        # vars = names(data)
        # arities = sapply(data, nlevels)
        # names(arities) = c()
        # varCnt = count_occurance(data, arities)
        # mbDiscrepancy = mb_discrepancy(vars, mbl)
        # mbl = sym_enforcement_mml(vars, varCnt, arities, n, mbl, mbDiscrepancy)
        # mbl = symmetry_correction(vars, mbl, "AND")
        # mblLen = sapply(mbl, length)
        # mblLen = mblLen[order(mblLen, decreasing = T)]
        # cat(mblLen, "\n")
        for (k in 1:length(mbt)) {
          edList[[j]][k] = mb_false_finding(mbt[[k]], mbl[[k]])
          retList[[j]] = c(retList[[j]], round(mb_retrieval(mbt[[k]], mbl[[k]], length(mbt)), 1))
        }
      }# end for j 
      
    }# end for i 
   
    avg_ed_over_all_nodes = paste0(round(conf_int(unlist(edList)), 1), collapse = "+-")
    retVec = unlist(retList)
    avg_pre_over_all_nodes = paste0(round(conf_int(retVec[!even(1:length(retVec))]), 1), collapse = "+-")
    avg_rec_over_all_nodes = paste0(round(conf_int(retVec[even(1:length(retVec))]), 1), collapse = "+-")
    avg_pre_rec_over_all_nodes = paste(avg_pre_over_all_nodes, avg_rec_over_all_nodes)
    m[ind, l] = avg_ed_over_all_nodes
    m[ind, l + 4] = avg_pre_rec_over_all_nodes
  }# end for n
  l = l + 1
}# end for each method

write.table(m, "~/Documents/Experiments/kdd_exp/kdd_results.csv", sep = ",", append = T, col.names = F, row.names = F)
# line = matrix(c(model, n, res), 1)
# write.table(line, "~/Documents/Experiments/kdd_exp/kdd_results.csv", sep = ",", append = T, col.names = F, row.names = F)
```

```{r}
m = matrix(unlist(edList), 25, length(mbt))
colMeans(m[1:5,])


```

## DAG stats
```{r}
dir = "~/Documents/Experiments/kdd_exp/"
model = "10_2_2_1"
mbs = list.files(paste0(dir, model, "/mb_true"))
for (x in mbs) {
  
  mbtrue = readRDS(paste0(dir, model, "/mb_true/", x))
  cat(sum(sapply(mbtrue, length)) / length(mbtrue), "\n")
  
}


```

















