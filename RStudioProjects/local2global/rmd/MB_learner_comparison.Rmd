---
title: "MB_learner_comparison"
author: "Kelvin Li"
date: "21 July 2017"
output: html_document
---

```{r global_options, include=F, warning=F, eval=F, echo=F, message=F}
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE, echo = F, eval = T)
if (.Platform$OS.type == "windows") {
  dir = "C:/Users/"
} else {
  dir = "/home/"
}
source(paste0(dir, "kl/Documents/PhDProjects/RStudioProjects/local2global/scripts/load_libraries.R"))
```

## Random model
```{r}
# dag = empty.graph(c("Y", paste0("X", 1:7)))
# for (i in 2:nnodes(dag)) {
#   dag = set.arc(dag, nodes(dag)[1], nodes(dag)[i])
# }
dag = randDag(5, 2)
graphviz.plot(dag)
cpts = randCPTs(dag, 2, 1)
sampleSize = n = 10
data = rbn(cpts, n)
vars = colnames(data)
arities = sapply(data, nlevels)
names(arities) = c()
# y = "V7"
# x = bnlearn::mb(dag, y)
# yIndex = which(vars == y)
# xIndices = which(vars %in% x)
# mb(dag, y)
```

## Executing MML_NB
```{r, eval = T}
#probSign = get_prob_sign(data)
lst_nb = list() 
for (i in 1:length(vars)) {
  #i=4
  y = vars[i]
  #forward_greedy(data, arities, vars, sampleSize, y, score = mml_nb_adaptive, debug = T)
  lst_nb[[i]] = forward_greedy(data, arities, vars, sampleSize, y, score = mml_nb_adaptive, debug = F)
  #forward_greedy(data, arities, vars, sampleSize, y, score = mml_nb, probSign = probSign, debug = T)
}

# Rprof("mml_nb.out")
# forward_greedy(data, arities, vars, sampleSize, "V4", score = mml_nb_adaptive, debug = F)
# Rprof(NULL)
# proftable("mml_nb.out")


## MML_CPT

indexListPerNodePerValue = count_occurance(data, arities)
lst_cpt = list()
for (i in 1:length(vars)) {
  y = vars[i]
  #forward_greedy_fast(data, indexListPerNodePerValue, arities, sampleSize, y, base = exp(1), debug =T)
  lst_cpt[[i]] = forward_greedy_fast(data, indexListPerNodePerValue, arities, sampleSize, y, base = exp(1), debug = F)
  #forward_greedy_fast(data, indexListPerNodePerValue, arities, sampleSize, vars[1], base = exp(1), debug = T)
}


## Accuracy

acc_nb = acc_cpt = acc_logit = matrix(0, nrow = length(vars), ncol = 2)
for (i in 1:length(vars)) {
  acc_nb[i, ] = classification_accuracy_mb(mb(dag, vars[i]), lst_nb[[i]], vars, vars[i])
}

for (i in 1:length(vars)) {
  acc_cpt[i, ] = classification_accuracy_mb(mb(dag, vars[i]), lst_cpt[[i]], vars, vars[i])  
}

# for (i in 1:length(vars)) {
#   acc_logit[i, ] = classification_accuracy_mb(mb(dag, vars[i]), lst_logit[[i]], vars, vars[i])  
# }

x1 = round(colMeans(acc_nb), 2)
x2 = round(1.96 * apply(acc_nb, 2, sd) / sqrt(length(vars)), 2)
x3 = round(colMeans(acc_cpt), 2)
x4 = round(1.96 * apply(acc_cpt, 2, sd) / sqrt(length(vars)), 2)
# x5 = round(colMeans(acc_logit), 2)
# x6 = round(1.96 * apply(acc_logit, 2, sd) / sqrt(length(vars)), 2)

cat("--------Accuracy over all nodes-------- \n")
cat("mml_nb:", x1[1], "(", x2[1], ")", x1[2], "(", x2[2], ") \n")
cat("mml_cpt:", x3[1], "(", x4[1], ")", x3[2], "(", x4[2], ") \n")
# cat("mml_logit:", x5[1], "(", x6[1], ")", x5[2], "(", x6[2], ") \n")

## Accuracy over root nodes
vars2 = c()
for (i in 1:length(vars)){
  if (length(bnlearn::parents(dag, vars[i])) < 1) vars2 = c(vars2, i)
}

x1 = round(colMeans(acc_nb[vars2,]), 2)
x2 = round(1.96 * apply(acc_nb[vars2,], 2, sd) / sqrt(length(vars)), 2)
x3 = round(colMeans(acc_cpt[vars2,]), 2)
x4 = round(1.96 * apply(acc_cpt[vars2,], 2, sd) / sqrt(length(vars)), 2)
cat("--------Accuracy over root nodes-------- \n")
cat("mml_nb:", x1[1], "(", x2[1], ")", x1[2], "(", x2[2], ") \n")
cat("mml_cpt:", x3[1], "(", x4[1], ")", x3[2], "(", x4[2], ") \n")

lst_nb = symmetry_correction(vars, lst_nb, "AND")
lst_cpt = symmetry_correction(vars, lst_cpt, "AND")

acc_nb = acc_cpt = acc_logit = matrix(0, nrow = length(vars), ncol = 2)
for (i in 1:length(vars)) {
  acc_nb[i, ] = classification_accuracy_mb(mb(dag, vars[i]), lst_nb[[i]], vars, vars[i])
}

for (i in 1:length(vars)) {
  acc_cpt[i, ] = classification_accuracy_mb(mb(dag, vars[i]), lst_cpt[[i]], vars, vars[i])  
}

# for (i in 1:length(vars)) {
#   acc_logit[i, ] = classification_accuracy_mb(mb(dag, vars[i]), lst_logit[[i]], vars, vars[i])  
# }

x1 = round(colMeans(acc_nb), 2)
x2 = round(1.96 * apply(acc_nb, 2, sd) / sqrt(length(vars)), 2)
x3 = round(colMeans(acc_cpt), 2)
x4 = round(1.96 * apply(acc_cpt, 2, sd) / sqrt(length(vars)), 2)
# x5 = round(colMeans(acc_logit), 2)
# x6 = round(1.96 * apply(acc_logit, 2, sd) / sqrt(length(vars)), 2)
cat("-----------------symmetry correction----------------------- \n")
cat("mml_nb:", x1[1], "(", x2[1], ")", x1[2], "(", x2[2], ") \n")
cat("mml_cpt:", x3[1], "(", x4[1], ")", x3[2], "(", x4[2], ") \n")
# cat("mml_logit:", x5[1], "(", x6[1], ")", x5[2], "(", x6[2], ") \n")

## Nodes that has no parents
vars2 = c()
for (i in 1:length(vars)){
  if (length(bnlearn::parents(dag, vars[i])) < 1) vars2 = c(vars2, i)
}

x1 = round(colMeans(acc_nb[vars2,]), 2)
x2 = round(1.96 * apply(acc_nb[vars2,], 2, sd) / sqrt(length(vars)), 2)
x3 = round(colMeans(acc_cpt[vars2,]), 2)
x4 = round(1.96 * apply(acc_cpt[vars2,], 2, sd) / sqrt(length(vars)), 2)
cat("---------------------------------------- \n")
cat("mml_nb:", x1[1], "(", x2[1], ")", x1[2], "(", x2[2], ") \n")
cat("mml_cpt:", x3[1], "(", x4[1], ")", x3[2], "(", x4[2], ") \n")
```

## MML_Logit

```{r, eval = F}
dataNumeric = factor2numeric(data)
vars = names(data)
sampleSize = n
lst_logit = list()
for (i in 1:length(vars)) {
  y = vars[i]
  lst_logit[[i]] = forward_greedy(data, arities, vars, sampleSize, y, score = mml_logit, dataNumeric = dataNumeric, debug = F)
  #forward_greedy(data, arities, vars, sampleSize, vars[1], score = mml_logit, dataNumeric = dataNumeric, debug = T)
}
```


## Real models
Used a different log factorial estimation, so the results could be different from when previous UAI results
```{r}
model = "alarm"
sampleSize = 500
score = "mml_nb"
```

```{r}
datasets = list.files(paste0("~/Documents/Experiments/UAI_exp/", model, "/data_csv/", sampleSize, "/"))
dag = readRDS(paste0("~/Documents/Experiments/UAI_exp/", model, "/dag/", model, ".rds"))
vars = bnlearn::nodes(dag)
```

```{r}
for (i in 1:length(datasets)) {
  data = read.csv(paste0("~/Documents/Experiments/UAI_exp/", model, "/data_csv/", sampleSize, "/", datasets[i]))  
  data = numeric2categorical(data)
  arities = sapply(data, nlevels)
  names(arities) = c()
  if (score == "mml_cpt") indexListPerNodePerValue = count_occurance(data, arities)
  lst_learned = list() 
  for (j in 1:length(vars)) {
    y = vars[j]
    if (score == "mml_nb") {
      lst_learned[[j]] = forward_greedy(data, arities, vars, sampleSize, y, score = mml_nb_adaptive)
    } else if (score == "mml_cpt") {
      lst_learned[[j]] = forward_greedy_fast(data, indexListPerNodePerValue, arities, sampleSize, y, base = exp(1))
    }
  }
  filename = strsplit(datasets[i], ".csv")[[1]]
  saveRDS(lst_learned, paste0("~/Documents/Experiments/mb_discovery/", model, "/", score, "/", sampleSize, "/without_symmetry/", filename, ".rds"))
  lst_learned = symmetry_correction(vars, lst_learned, "AND")
  saveRDS(lst_learned, paste0("~/Documents/Experiments/mb_discovery/", model, "/", score, "/", sampleSize, "/with_symmetry/", filename, ".rds"))
}
```

```{r}
model = "insurance"
score = "mml_nb"
sampleSize = 500
dag = readRDS(paste0("~/Documents/Experiments/UAI_exp/", model, "/dag/", model, ".rds"))
vars = bnlearn::nodes(dag)
mb_true = list()
for (i in 1:length(vars)) {
  mb_true[[i]] = bnlearn::mb(dag, vars[i])
}
files = list.files(paste0("~/Documents/Experiments/mb_discovery/", model, "/", score, "/", sampleSize, "/without_symmetry/"))
sum_ed = rep(0, length(files))
accuracy = c(0, 0)
for (i in 1:length(files)) {
  mb_learned = readRDS(paste0("~/Documents/Experiments/mb_discovery/", model, "/", score, "/", sampleSize, "/without_symmetry/", files[i]))
  #mb_learned = symmetry_correction(vars, lst_learned, "OR")
  #ee = c()
  for (j in 1:length(vars)) {
  #for (j in vars2) {
    y = vars[j]
    #cat(edit_dist_mb(mb_true[[j]], mb_learned[[j]], vars, y), "\n")
    accuracy = accuracy + classification_accuracy_mb(mb_true[[j]], mb_learned[[j]], vars, y)
    #sum_ed[i] = sum_ed[i] + edit_dist_mb(mb_true[[j]], mb_learned[[j]], vars, y)
  }
}

accuracy/(10*length(vars))

#c = 1.96 * sd(sum_ed) / sqrt(length(sum_ed))
#cat(mean(sum_ed), "+/-", c)
```

```{r}
for (i in 1:length(vars)) {
  cat(length(bnlearn::mb(dag, vars[i])) - length(bnlearn::parents(dag, vars[i])) - length(bnlearn::children(dag, vars[[i]])), "\n")
}
```






