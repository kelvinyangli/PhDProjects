---
title: "mml_rand_str"
author: "kl"
date: "6 January 2018"
output: pdf_document
---

```{r global_options, include=F, warning=F, eval=F, echo=F, message=F}
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE, echo = F, eval = T)
if (.Platform$OS.type == "windows") {
  dir = "C:/Users/"
} else {
  dir = "/home/"
}
source(paste0(dir, "kl/Documents/PhDProjects/RStudioProjects/local2global/scripts/load_libraries.R"))

# cpt = read.dsc("~/Downloads/barley.dsc.gz")
# a = c()
# for (i in 1:length(cpt)) {
#   a = c(a, nrow(cpt[[i]]$prob))
# }
# saveRDS(a, "~/Documents/Experiments/UAI_exp/barley/arities.rds")
```

```{r}
# library(parallel)
# library(foreach)
# library(doParallel)

dag = randDag(10, 3)
cpts = randCPTs(dag, 4, 1)
data = rbn(cpts, 1000)
arities = sapply(data, nlevels)
names(arities) = c()
vars = colnames(data)
n = nrow(data)
di = count_occurance(data, arities)
data = data.matrix(data)

for (target in vars) {
  res = forward_greedy(data, arities, vars, n, target, "random", varCnt = di, prior = "uniform")
  #cat(res, "\n")
} 

#no_cores = detectCores() - 1
no_cores = 3
registerDoParallel(no_cores)
ll = foreach(target = vars, 
        .combine = list, 
        .multicombine = TRUE) %dopar%
  forward_greedy(data, arities, vars, n, target, "random", varCnt = di, prior = "uniform")
stopImplicitCluster()

```

## Testing on real models.
## without sym: rand 24.5--2.11; 20.7 +- 1.85; cpt 25.5--1.02; nb 24.4--2.82; 
## with sym: rand 25.4--3.79; 19.4 +- 3.09; cpt 18--1.94; 31.2--4.61; find a way to drop the ed for rand after symmetry check!!!

## rand (with 100 SEC samples)
## without sym: 22.8 +- 1.59; 17.1 +- 1.66;
## with sym: 27.2 +- 2.42; 18.6 +- 2.41;
```{r}
model = "barley"
modelDir = paste0("~/Documents/Experiments/UAI_exp/", model, "/")
resultsDir = "~/Documents/Experiments/kdd_exp/"
dag = readRDS(paste0(modelDir, "dag/", model, ".rds"))
n = sampleSize = 5000
vars = bnlearn::nodes(dag)
nvars = length(vars)
#arities = readRDS(paste0("~/Documents/Experiments/UAI_exp/", model, "/arities.rds"))
datasets = list.files(paste0(modelDir, "data_csv/", n, "/"))


### starting parallel computing ###
no_cores = 3
registerDoParallel(no_cores)
for (i in 1:length(datasets)) {
  cat(i, "\n")
  filename = strsplit(datasets[i], ".csv")[[1]]
  mbcpt = mbnb = mbrand = mbiamb = mbinteriamb = list()
  data = read.csv(paste0(modelDir, "data_csv/", n, "/", datasets[i])) 
  data = numeric2categorical(data)
  arities = sapply(data, nlevels)
  #for (j in 1:ncol(data)) levels(data[, j]) = 0:(arities[j] - 1)
  
  # mbiamb = sapply(vars, learn.mb, x = data, method = "iamb")
  # saveRDS(mbiamb, paste0(resultsDir, model, "/iamb/", n, "/without_symmetry/", filename, ".rds"))
  # 
  # mbinteriamb = sapply(vars, learn.mb, x = data, method = "inter.iamb")
  # saveRDS(mbinteriamb, paste0(resultsDir, model, "/inter_iamb/", n, "/without_symmetry/", filename, ".rds"))
  
  di = count_occurance(data, arities)
  data = data.matrix(data)
  
  mbrand = foreach(target = vars,
      .combine = list,
      .multicombine = TRUE) %dopar%
    forward_greedy(data, arities, vars, n, target, "random", varCnt = di, prior = "uniform")

  mbrand_sym = symmetry_correction(vars, mbrand, "AND")
  saveRDS(mbrand, paste0(resultsDir, model, "/mml_rand/", n, "/without_symmetry/", filename, ".rds"))
  saveRDS(mbrand_sym, paste0(resultsDir, model, "/mml_rand/", n, "/with_symmetry/", filename, ".rds"))

  mbcpt = foreach(target = vars,
      .combine = list,
      .multicombine = TRUE) %dopar%
    forward_greedy_fast(data, di, arities, vars, n, target)

  mbcpt_sym = symmetry_correction(vars, mbcpt, "AND")
  saveRDS(mbcpt, paste0(resultsDir, model, "/mml_cpt/", n, "/without_symmetry/", filename, ".rds"))
  saveRDS(mbcpt_sym, paste0(resultsDir, model, "/mml_cpt/", n, "/with_symmetry/", filename, ".rds"))

  mbnb = foreach(target = vars,
      .combine = list,
      .multicombine = TRUE) %dopar%
    forward_greedy(data, arities, vars, n, target, "nb")

  mbnb_sym = symmetry_correction(vars, mbnb, "AND")
  saveRDS(mbnb, paste0(resultsDir, model, "/mml_nb/", n, "/without_symmetry/", filename, ".rds"))
  saveRDS(mbnb_sym, paste0(resultsDir, model, "/mml_nb/", n, "/with_symmetry/", filename, ".rds"))
  
}

stopImplicitCluster()
```

## Forcing symmetry
```{r}
model = "hailfinder"
method = "inter_iamb"
for (n in c(500, 1000, 5000)) {
  
  modelDir = paste0("~/Documents/Experiments/UAI_exp/", model, "/")
  dag = readRDS(paste0(modelDir, "dag/", model, ".rds"))
  vars = bnlearn::nodes(dag)
  
  files = list.files(paste0("~/Documents/Experiments/kdd_exp/", model, "/", method, "/", n, "/without_symmetry/"))
  for (i in 1:length(files)) {
    mbl = readRDS(paste0("~/Documents/Experiments/kdd_exp/", model, "/", method, "/", n, "/without_symmetry/", files[i]))
    mbl = symmetry_correction(vars, mbl, "AND")
    saveRDS(mbl, paste0("~/Documents/Experiments/kdd_exp/", model, "/", method, "/", n, "/with_symmetry/", files[i]))
  }
  
}

```

## Evaluating
```{r}
model = "hailfinder"
dir = paste0("~/Documents/Experiments/UAI_exp/", model, "/")
dag = readRDS(paste0(dir, "dag/", model, ".rds"))
vars = bnlearn::nodes(dag)
nvars = length(vars)
# true mbs 
mbtrue = sapply(vars, bnlearn::mb, x = dag)

for (n in c(500, 1000, 5000)) {
  
  sed = ret = c()
  for (method in c("mml_cpt", "mml_nb", "mml_rand", "iamb", "inter_iamb")) {
  
    #method = "mml_rand"
    symtry = "without"
    files = list.files(paste0("~/Documents/Experiments/kdd_exp/", model, "/", method, "/", n, "/", symtry, "_symmetry/"))
    #cat(length(files), "\n")
    edrand = rep(list(rep(0, nvars)), length(files))
    retRand = matrix(0, length(files) * nvars, 2)
    k = 1
    for (i in 1:length(files)) {
      mbrand = readRDS(paste0("~/Documents/Experiments/kdd_exp/", model, "/", method, "/", n, "/", symtry, "_symmetry/", files[i]))
      for (j in 1:length(mbrand)) {
        edrand[[i]][j] = mb_false_finding(mbtrue[[j]], mbrand[[j]])
        retRand[k, ] = mb_retrieval(mbtrue[[j]], mbrand[[j]], nvars)
        k = k + 1
      }
    }
    
    x = round(apply(retRand, 2, mean), 2)
    y = round(1.96 * apply(retRand, 2, sd) / sqrt(nrow(retRand)), 2)
    ret = c(ret, paste(paste0(c(x[1], y[1]), collapse = "+-"), " ", paste0(c(x[2], y[2]), collapse = "+-")))
    
    x = round(mean(sapply(edrand, sum)), 2)
    y = round(1.96 * sd(unlist(lapply(edrand, sum))) / sqrt(10), 2)
    sed = c(sed, paste0(c(x, y), collapse = "+-"))
    
  }
  
  if (symtry == "with") {
    sym = "Y"
  } else {
    sym = "N"
  }
  
  line = matrix(c(model, n, sed, ret, sym), 1)
  write.table(line, "~/Documents/Journal KDD/test_results_v2.csv",
              sep = ",", append = T, col.names = F, row.names = F)

}

```


## Testing cpt, nb, and rand models. Results are printed in .csv
```{r}
#for (itr in 1:3) {
  
nvars = 10
maxpa = 3
dag_sd = randSeed()
#dag_sd = 9008
set.seed(dag_sd)
dag = randDag(nvars, maxpa)

maxarity = 3
beta = 1
cpts_sd = randSeed()
#cpts_sd = 94026
set.seed(cpts_sd)
cpts = randCPTs(dag, maxarity, beta)

n = sampleSize = 1000
data_sd = randSeed()
#data_sd = 100188
set.seed(data_sd)
data = rbn(cpts, n)
vars = colnames(data)
arities = sapply(data, nlevels)
names(arities) = c()
varCnt = count_occurance(data, arities)
data = data.matrix(data)
nvars = length(vars)
i = 1
lrand = lrand2 = lcpt = lnb = list()
ltrue = sapply(vars, bnlearn::mb, x = dag)

forward_greedy(data, arities, vars, n, "V4", "random", varCnt = varCnt, prior = "uniform", dag = dag, debug=T)

no_cores = 3
registerDoParallel(no_cores)
lrand = foreach(target = vars, 
        .combine = list, 
        .multicombine = TRUE) %dopar%
  forward_greedy(data, arities, vars, n, target, "random", varCnt = varCnt, prior = "uniform")

lcpt = foreach(target = vars, 
        .combine = list, 
        .multicombine = TRUE) %dopar%
  forward_greedy_fast(data, varCnt, arities, vars, n, target)

lnb = foreach(target = vars, 
        .combine = list, 
        .multicombine = TRUE) %dopar%
  forward_greedy(data, arities, vars, n, target, "nb")


stopImplicitCluster()

# for (target in vars) {
#   
#   cat(i, "\n")
#   #target = "V1"
#   # f2 overally reduce mml score, not penalizing bad model and in favor to good models
#   # need to think about a more sutiable prior
#   # lrand2[[i]] = f2(dag, data,di,arities,vars,target,n,F)
#   ltrue[[i]] = bnlearn::mb(dag, target)
#   lrand[[i]] = forward_greedy(data, arities, vars, n, target, "random", varCnt = di,
#                               prior = "uniform", debug = T)
#   lcpt[[i]] = forward_greedy_fast(data, di, arities, vars, n, target, debug = F)
#   lnb[[i]] = forward_greedy(data, arities, vars, n, target, "nb", debug = F)
#   i = i + 1
#   
# }

i = 1
arand = arand2 = acpt = anb = rep(0, nvars)
crand = crand2 = ccpt = cnb = matrix(0, nvars, 2)
m = p = c = s = rep(0, nvars)
mbl = list()
for (target in vars) {
  
  mbl[[i]] = bnlearn::mb(dag, target)
  m[i] = length(mbl[[i]])
  p[i] = length(bnlearn::parents(dag, target))
  c[i] = length(bnlearn::children(dag, target))
  s[i] = m[i] - p[i] - c[i]
  arand[i] = mb_false_finding(mbl[[i]], lrand[[i]])
  crand[i, ] = mb_retrieval(mbl[[i]], lrand[[i]], nvars)
  # arand2[i] = mbEditDist(mbl[[i]], lrand2[[i]], target, vars)
  # crand2[i, ] = classfication_accuracy_mb(mbl[[i]], lrand2[[i]], vars, target)
  acpt[i] = mb_false_finding(mbl[[i]], lcpt[[i]])
  ccpt[i, ] = mb_retrieval(mbl[[i]], lcpt[[i]], nvars)
  anb[i] = mb_false_finding(mbl[[i]], lnb[[i]])
  cnb[i, ] = mb_retrieval(mbl[[i]], lnb[[i]], nvars)
  i = i + 1
  
}

dag_stats = c(nvars, maxpa, maxarity, n)

ed_cpt = paste(round(mean(acpt), 2), round(1.96 * sd(acpt) / sqrt(n), 2))
ed_nb = paste(round(mean(anb), 2), round(1.96 * sd(anb) / sqrt(n), 2))
ed_rand = paste(round(mean(arand), 2), round(1.96 * sd(arand) / sqrt(n), 2))
#ed_rand2 = paste(round(mean(arand2), 2), round(1.96 * sd(arand2) / sqrt(n), 2))
ed_rand2 = 0

line = matrix(c(dag_stats, ed_cpt, ed_nb, ed_rand, ed_rand2), 1, 8)
cat(line)
# # write.table(line, "~/Documents/Journal KDD/test_results.csv", sep = ",", append = T, col.names = F, row.names = F)
# 
# pred_cpt = paste(round(apply(ccpt, 2, mean), 2), collapse = " ")
# pred_nb = paste(round(apply(cnb, 2, mean), 2), collapse = " ")
# pred_rand = paste(round(apply(crand, 2, mean), 2), collapse = " ")
# #pred_rand2 = paste(round(apply(crand2, 2, mean), 2), collapse = " ")
# pred_rand2 = "0"
# 
# # line = matrix(c(0, dag_sd, cpts_sd, data_sd, pred_cpt, pred_nb, pred_rand, pred_rand2), 1, 8)
# # write.table(line, "~/Documents/Journal KDD/test_results.csv", sep = ",", append = T, col.names = F, row.names = F)
# 
# ###################### sym check ###################### 
# llrand = symmetry_correction(vars, lrand, "AND")
# # llrand2 = symmetry_correction(vars, lrand2, "AND")
# llcpt = symmetry_correction(vars, lcpt, "AND")
# llnb = symmetry_correction(vars, lnb, "AND")
# 
# aarand = aarand2 = aacpt = aanb = rep(0, nvars)
# ccrand = ccrand2 = cccpt = ccnb = matrix(0, nvars, 2)
# i = 1
# for (target in vars) {
#   
#   aarand[i] = mbEditDist(mbl[[i]], llrand[[i]], target, vars)
#   ccrand[i, ] = classfication_accuracy_mb(mbl[[i]], llrand[[i]], vars, target)
#   # aarand2[i] = mbEditDist(mbl[[i]], llrand2[[i]], target, vars)
#   # ccrand2[i, ] = classfication_accuracy_mb(mbl[[i]], llrand2[[i]], vars, target)
#   aacpt[i] = mbEditDist(mbl[[i]], llcpt[[i]], target, vars)
#   cccpt[i, ] = classfication_accuracy_mb(mbl[[i]], llcpt[[i]], vars, target)
#   aanb[i] = mbEditDist(mbl[[i]], llnb[[i]], target, vars)
#   ccnb[i, ] = classfication_accuracy_mb(mbl[[i]], llnb[[i]], vars, target)
#   i = i + 1
#   
# }
# 
# dag_stats = c(nvars, maxpa, maxarity, n)
# 
# ed_cpt = paste(round(mean(aacpt), 2), round(1.96 * sd(aacpt) / sqrt(n), 2))
# ed_nb = paste(round(mean(aanb), 2), round(1.96 * sd(aanb) / sqrt(n), 2))
# ed_rand = paste(round(mean(aarand), 2), round(1.96 * sd(aarand) / sqrt(n), 2))
# #ed_rand2 = paste(round(mean(arand2), 2), round(1.96 * sd(arand2) / sqrt(n), 2))
# ed_rand2 = 0
# 
# # line = matrix(c(dag_stats, ed_cpt, ed_nb, ed_rand, ed_rand2), 1, 8)
# # write.table(line, "~/Documents/Journal KDD/test_results.csv", sep = ",", append = T, col.names = F, row.names = F)
# 
# pred_cpt = paste(round(apply(cccpt, 2, mean), 2), collapse = " ")
# pred_nb = paste(round(apply(ccnb, 2, mean), 2), collapse = " ")
# pred_rand = paste(round(apply(ccrand, 2, mean), 2), collapse = " ")
# #pred_rand2 = paste(round(apply(crand2, 2, mean), 2), collapse = " ")
# pred_rand2 = "0"
# 
# # line = matrix(c(0, dag_sd, cpts_sd, data_sd, pred_cpt, pred_nb, pred_rand, pred_rand2), 1, 8)
# # write.table(line, "~/Documents/Journal KDD/test_results.csv", sep = ",", append = T, col.names = F, row.names = F)
# 
# #}
```

## An alternative mml_rand function that uses differnt prior for averaging msg len
```{r}
f2 = function(dag, data, di, arities, vars, target, n, debug = FALSE) {
  
  targetIndex = which(vars == target)
  targetProbsAdpt = probs_adaptive(data, arities, n, targetIndex)
  unchecked = vars[vars != target]
  cmb = c()
  min_l = mml_nb_adaptive(data, arities, targetIndex, c())
  str = local_extraction(dag, c(target, bnlearn::mb(dag, target)))
  l_perfect = mml_fixed_str_adaptive(data, vars, arities, n, targetIndex, targetProbsAdpt, str)
  
  if (debug) cat(target, "perfect model:", bnlearn::mb(dag, target), "--score:", l_perfect, "\n")
  if (debug) cat("empty model:", min_l, "\n")
  repeat {
    
    temp_l = c()
    mbpts = readRDS(paste0("~/Documents/PhDProjects/RStudioProjects/local2global/MBPTs_ordered/", length(cmb) + 1, ".rds"))
    
    for (x in unchecked) {
      
      tempVars = c(cmb, x, target)
      l = rep(0, length(mbpts))
      for (i in 1:length(mbpts)) {
        
        pt = mbpts[[i]]
        dimnames(pt) = rep(list(tempVars), 2)
        pt = matrix2dag(pt)
        pa = bnlearn::parents(pt, target)
        ch = bnlearn::children(pt, target)
        if (length(pa) == (length(tempVars) - 1)) {
          
          res = mml_cpt(di, arities, n, which(vars %in% pa), targetIndex, base = exp(1))        
          
        } else if (length(ch) == (length(tempVars) - 1)) {
          
          res = mml_nb_adaptive(data, arities, targetIndex, which(vars %in% ch))
          
        } else {
          
          res = mml_fixed_str_adaptive(data, vars, arities, n, targetIndex, targetProbsAdpt, pt)
      
        }
        
        if (debug) cat(i, res, is_substr(dag, pt), "\n")
        l[i] = res
      }
      
      if (length(tempVars) == 4) {
        #l = l[-c(15,16,19,20,23)] # remove less probable str for now  
        ntoms = c(6,2,2,2,2,2,2,6,3,5,3,5,3,5,3,5,3,5,3,5,6,6,6)
        sec_l = c(l[1:4], mean(l[5:8]), mean(l[9:10]), mean(l[11:12]), mean(l[13:14]), mean(l[17:18]), l[21:22])
        sec_prior = c(ntoms[1:4], sum(ntoms[5:8]), sum(ntoms[9:10]), sum(ntoms[11:12]), sum(ntoms[13:14]), sum(ntoms[17:18]), ntoms[21:22]) / sum(ntoms[-c(15,16,19,20,23)])
      } else if (length(tempVars) == 3) {
        ntoms = c(2, 1, 1, 2, 2)
        l = l[-6]
        sec_l = c(l[1], mean(l[2:4]), l[5])
        sec_prior = c(ntoms[1], sum(ntoms[2:4]), ntoms[5]) / sum(ntoms)
      } else if (length(tempVars) == 2) {
        sec_l = mean(l)
        sec_prior = 1
      }
      
      
      avg_l = sum(sec_l * sec_prior)
      
      if (debug) cat(c(cmb, x), "--", avg_l, "\n")
      
      temp_l = c(temp_l, avg_l)
      local_min_l = min(temp_l)
      
    }
    
    if (min_l > local_min_l) {
        
      toadd = unchecked[which.min(temp_l)]
      cmb = c(cmb, toadd)
      if (debug) cat("cmb:", cmb, "--", local_min_l, "\n")
      unchecked = unchecked[-which.min(temp_l)]
      if (debug) cat("unchked", unchecked, "\n")
      min_l = local_min_l
        
    }
    
    if ((length(unchecked) < 1) || (local_min_l > min_l)) break
    
  }

  if (length(cmb) < 1) cmb = character(0)
  return(cmb)

}


# a function to extract the local str from a dag 


# a function to report whether the current local str is a true sub str of the generating dag
is_substr = function(dag, localStr) {
  
  contained = 1
  for (i in 1:nrow(localStr$arcs)) {
    
    indexFrom = which(localStr$arcs[i, 1] == dag$arcs[, 1])
    indexTo = which(localStr$arcs[i, 2] == dag$arcs[, 2])
    if (length(intersect(indexFrom, indexTo)) < 1) {
      
      contained = 0
      break
      
    }
    
  }
  
  return(contained)
  
}


```

## observations:
## when a true mb node is included for testing, the cpt model has lower score than the strs that are extended from the str that has the lowest score in the previous step; when a non-mb node is included for testing, the cpt model has higher score than the strs that are extended from the ...


## Testing mml_rand against cpt and nb on mb with pa and ch only. The first test fixes parameters but vary data, the edit dist are 3.82, 3.58, 2.8 for rand, cpt and nb over 50 datasets of 100 samples. The second test varies cpts and data, edit dist are 4, 3.54, 2.68 respectively. mml_nb wins!

## If three parents only, rand 1.34, cpt 1.80, nb 1.28; if three children only, rand 1.9, cpt 2.08, nb 1.32;
```{r}
vars = paste0("V", c(1:4))
nvars = length(vars)
dag = empty.graph(vars)
# dag = set.arc(dag, "V2", "V1")
# dag = set.arc(dag, "V3", "V1")
# dag = set.arc(dag, "V4", "V1")
# dag = set.arc(dag, "V1", "V5")
# dag = set.arc(dag, "V1", "V6")
# dag = set.arc(dag, "V1", "V7")
dag = set.arc(dag, "V1", "V2")
dag = set.arc(dag, "V1", "V3")
dag = set.arc(dag, "V1", "V4")

arities = rep(2, nvars)
target = "V1"
targetIndex = which(vars == target)
m = mb(dag, target)
n = 100
w = rep(0, 3)
for (t in 1:50) {
  
  cat(t, w, "\n")
  cpts = randCPTs(dag, 2, 1)
  data = rbn(cpts, n)
  di = count_occurance(data, arities)
  targetAdptProbs = adpt_code_prob_no_pa(data, arities, targetIndex, n)
  lrand = forward_greedy(data, arities, vars, n, target, "random", varCnt = di,
                                targetAdptProbs = targetAdptProbs, debug = F)
  lcpt = forward_greedy_fast(data, di, arities, n, target, debug = F)
  lnb = forward_greedy(data, arities, vars, n, target, "nb", debug = F)
  w[1] = w[1] + edit_dist_mb(m, lrand, vars, target)
  w[2] = w[2] + edit_dist_mb(m, lcpt, vars, target)
  w[3] = w[3] + edit_dist_mb(m, lnb, vars, target)
  
}
w / t
```

## Testing with spouses, varying data only 3.88, 4.06, 3.48 over 50 runs. Varying both cpts and data, 4.28, 4.12, 3.86. Testing with spouses, varying data only using f() taking weighted average according to mml score, results are 3.54, 4.26, 3.2; varying both cpts and data, 4.22, 4.22, 3.78; if three parents and others are isolated, cpt 2.02, nb 2; if three children and others are isolated, cpt 1.86, nb 1.9; if two children two spouses only, 2.88, 3.34, 2.66; 
```{r}
vars = paste0("V", c(1,4,5,6,7))
nvars = length(vars)
dag = empty.graph(vars)
# dag = set.arc(dag, "V2", "V1")
# dag = set.arc(dag, "V3", "V1")
# dag = set.arc(dag, "V4", "V1")
dag = set.arc(dag, "V4", "V5")
dag = set.arc(dag, "V1", "V5")
dag = set.arc(dag, "V1", "V6")
# dag = set.arc(dag, "V1", "V7")
dag = set.arc(dag, "V7", "V6")
arities = rep(2, nvars)
target = "V1"
targetIndex = which(vars == target)
m = mb(dag, target)
n = 100
w = rep(0, 3)

for (t in 1:50) {
  
  cat(t, ":", w, "\n")
  cpts = randCPTs(dag, 2, 1)
  data = rbn(cpts, n)
  di = count_occurance(data, arities)
  lrand = f(data,di,arities,vars,target,n)
  
  targetAdptProbs = adpt_code_prob_no_pa(data, arities, targetIndex, n)
  lrand = forward_greedy(data, arities, vars, n, target, "random", varCnt = di,
                                targetAdptProbs = targetAdptProbs, debug = F)
  lcpt = forward_greedy_fast(data, di, arities, n, target, debug = F)
  lnb = forward_greedy(data, arities, vars, n, target, "nb", debug = F)
  w[1] = w[1] + edit_dist_mb(m, lrand, vars, target)
  w[2] = w[2] + edit_dist_mb(m, lcpt, vars, target)
  w[3] = w[3] + edit_dist_mb(m, lnb, vars, target)
  
}
w / t
```

## using TOM prior in camml (f2 uses tom prior adds up to the sec level, results are occationaly better); 
## also through in the true str score, it should win in most case, perhaps loss in small samples (exp results confirmed this, (subgraph of) true model has better score most of the time, but not always expecially under small samples); 
## testing random; sanity check, should be uniform, 100 smaples uniform is 100. 

## need a function to calculate tom prior, a function to generate sec
```{r}
dag = randDag(7, 3)
#graphviz.plot(dag)
cpts = randCPTs(dag, 3, 1)
n = 100
data = rbn(cpts, n)
vars = colnames(data)
arities = sapply(data, nlevels)
names(arities) = c()
di = count_occurance(data, arities)
nvars = length(vars)
#graphviz.plot(dag)
for (target in vars) {
  #target = "V1"
  targetIndex = which(vars == target)
  targetAdptProbs = adpt_code_prob_no_pa(data, arities, targetIndex, n)
  r1 = f(dag, data,di,arities,vars,target,n, debug = F)
  r2 = f2(dag, data,di,arities,vars,target,n, debug = F)
  cat(r1, "\n")
  cat(r2, "\n")
}
# forward_greedy(data, arities, vars, n, target, "random", varCnt = di, targetAdptProbs = targetAdptProbs, debug = T)
# str = local_extraction(dag, c(target, bnlearn::mb(dag, target)))
# graphviz.plot(str)
# mml_rand_str(str, data, vars, arities, targetAdptProbs, targetIndex, n)
```

### testing true dag and true polytree's mml score
```{r}
vars = c("V1", "V2", "T")
nvars = length(vars)
dag = empty.graph(vars)
dag = set.arc(dag, "T", "V1")
dag = set.arc(dag, "T", "V2")
dag = set.arc(dag, "V1", "V2")
target = "T"
targetIndex = which(vars == target)
mbpts = readRDS("~/Documents/PhDProjects/RStudioProjects/local2global/MBPTs/2.rds")
maxArity = 2
n = 500
nitr = 10
r = rep(0, nitr)
for (i in 1:nitr) {
  l = rep(0, length(mbpts) + 1)
  cpts = randCPTs(dag, maxArity, 1)
  data = rbn(cpts, n)
  arities = sapply(data, nlevels)
  names(arities) = c()
  targetAdptProbs = adpt_code_prob_no_pa(data, arities, targetIndex, n)
  l[length(l)] = mml_rand_str(dag, data, vars, arities, targetAdptProbs, targetIndex, n)
  
  for (j in 1:length(mbpts)) {
    pt = mbpts[[j]]
    dimnames(pt) = list(vars, vars)
    pt = matrix2dag(pt)
    l[j] = mml_rand_str(pt, data, vars, arities, targetAdptProbs, targetIndex, n)
  }
  cat(l, "\n")
  r[i] = which.min(l)
}

length(which(r == 1))
length(which(r == 2))
length(which(r == 3))
length(which(r == 4))
length(which(r == 5))
length(which(r == 6))
length(which(r == 7))

```
## Splitting MBPTs into SECs.
```{r}
for (m in 1:7) {
  mbpts = readRDS(paste0("~/Documents/PhDProjects/RStudioProjects/local2global/MBPTs_ordered/", m, ".rds"))
  ecs = ecsInd = list()
  k = 2
  ecs[[1]] = dag2matrix(cpdag(matrix2dag(mbpts[[1]])))
  ecsInd[[1]] = 1
  for (i in 2:length(mbpts)) {
    res = dag2matrix(cpdag(matrix2dag(mbpts[[i]])))
    ind = which(unlist(lapply(ecs, all.equal, current = res)) == "TRUE") 
    if (length(ind) > 0) {
      ecsInd[[ind]] = c(ecsInd[[ind]], i)
    } else {
      ecs[[k]] = res
      ecsInd[[k]] = i
      k = k + 1
    }
  }
  #cat(m, "--", length(mbpts), "--", length(ecs), "\n")
  saveRDS(ecsInd, paste0("~/Documents/PhDProjects/RStudioProjects/local2global/MBPT_SECsInd/", m, ".rds"))
  saveRDS(ecs, paste0("~/Documents/PhDProjects/RStudioProjects/local2global/MBPT_SECs/", m, ".rds"))
}

ind = list()
for (m in 1:7) {
  temp = c()
  mbpts = readRDS(paste0("~/Documents/PhDProjects/RStudioProjects/local2global/MBPT_SECs/", m, ".rds"))
  for (i in 1:length(mbpts)) {
    str = mbpts[[i]]
    if (sum(str[1:(ncol(str) - 2), ncol(str) - 1]) > 0) {
      temp = c(temp, i)
    }
  }
  cat(temp, "\n")
  ind[[m]] = temp
}
```

## TOM prior
```{r}
vars = c(paste0("V", 1:2), "T")

toms = function(vars, target) {
  
  nodeOrderings = permutations(length(vars), length(vars), vars)
  allEdges = combinations(length(vars), 2)
  edges = combinations(nrow(allEdges), length(vars) - 1)
  lst = list()
  lInd = 1
  for (i in 1:nrow(nodeOrderings)) {
    
    for (j in 1:nrow(edges)) {
      
      tom = matrix(0, length(vars), length(vars), dimnames = rep(list(nodeOrderings[i, ]), 2))
      for (k in 1:ncol(edges)) {
        
        # check if an edge contradicts node ordering, if yes then remove it
        allEdgesRowID = edges[j, k]
        pa = allEdges[allEdgesRowID, 1]
        ch = allEdges[allEdgesRowID, 2]
        tom[pa, ch] = 1
        
        # check if the tom satisfies mb adjacencies
        # it is definitely a polytree since the number of edges are restricted to nvars - 1
        if (mb_adj_check(tom, target)) {
          
          lst[[lInd]] = tom
          lInd = lInd + 1
          
        } # end checking mb adjacencies
          
      } # end for k
      
    }# end for j
    
  }
  
  return(lst)
    
}


mb_adj_check = function(str, target) {
  
  if (!target %in% colnames(str)) warning("Invalid target")
  
  isMB = 1
  targetStrInd = which(colnames(str) == target)
  pa = which(str[, targetStrInd] == 1)
  ch = which(str[targetStrInd, ] == 1)
  others = (1:ncol(str))[-c(targetStrInd, pa, ch)]
  if (length(pa) + length(ch) < ncol(str) - 1) {
  
    for (x in others) {
      
      if (sum(str[x, ch]) == 0) {# it means x isn't a parent of at least one other child of the target
        
       isMB = 0
       break
       
      } # end if 
      
    } # end x in others
      
  }
  
  return(isMB)
  
}


```


```{r}
sym_enforcement_mml = function(vars, varCnt, arities, sampleSize, mbl, mbDiscrepancy) {
  
  mblSym = mbl
  for (i in 1:nrow(mbDiscrepancy)) {
  
    targetIndex1 = abs(mbDiscrepancy[[i, 1]])
    mbIndices1 = which(vars %in% mbl[[targetIndex1]])
    I1 = mml_cpt(varCnt, arities, sampleSize, mbIndices1, targetIndex1)
    mbIndices1 = mbIndices1[!mbIndices1 == abs(mbDiscrepancy[[i, 2]])] # remove an extra var
    I1 = mml_cpt(varCnt, arities, sampleSize, mbIndices1, targetIndex1) - I1  
    
    targetIndex2 = mbDiscrepancy[[i, 2]]
    mbIndices2 = which(vars %in% mbl[[targetIndex2]])
    I2 = mml_cpt(varCnt, arities, sampleSize, mbIndices2, targetIndex2)
    mbIndices2 = c(mbIndices2, abs(mbDiscrepancy[[i, 1]])) # add a missing var
    I2 = mml_cpt(varCnt, arities, sampleSize, mbIndices2, targetIndex2) - I2
    
    cat(I1, ":", I2, "\n")
    
    if (((I1 > 0) && (I2 > 0)) || ((I1 < 0) && (I2 < 0))) {
      
      if (abs(I1) > abs(I2)) {
        
        mblSym[[targetIndex2]] = vars[mbIndices2]
        
      } else {
        
        mblSym[[targetIndex1]] = vars[mbIndices1]
        
      }
      
    } else {# when I1 and I2 have different signs
      
      if (I1 > I2) {
        
        mblSym[[targetIndex2]] = vars[mbIndices2]
        
      } else {
        
        mblSym[[targetIndex1]] = vars[mbIndices1]
        
      }
      
    }
    
  }
  
  return(mblSym)
  
}


mb_discrepancy = function(vars, mbl) {
  
  dis = data.frame()
  for (i in 1:length(vars)) {
    
    if (length(mbl[[i]]) > 0) {
      
      for (j in 1:length(mbl[[i]])) {
        
        ind = which(vars == mbl[[i]][j])
        if (!vars[i] %in% mbl[[ind]]) dis = rbind(dis, c(-i, ind))
        
      }
    
    }
    
  }
  
  colnames(dis) = c()
  return(dis)
  
}
```









