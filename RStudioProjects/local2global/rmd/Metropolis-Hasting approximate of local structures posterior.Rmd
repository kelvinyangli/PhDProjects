---
title: "Metropolis-Hasting approximate of local structures posterior"
author: "Kelvin Li"
date: "19 March 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE, echo = F, eval = T)
if (.Platform$OS.type == "windows") {
  dir = "C:/Users/"
} else {
  dir = "/home/"
}
source(paste0(dir, "kl/Documents/PhDProjects/RStudioProjects/local2global/scripts/load_libraries.R"))
```


```{r}
randData = function(cpts, n) {
  
  dt = rbn(cpts, n)
  arities = sapply(dt, nlevels)
  vars = colnames(dt)
  lst = list(vars = vars, arities = arities, data = dt)
  return(lst)
  
}
```


## Score a local structure

This function calculates I(D, H). It is the same as mml_fixed_str_adaptive, but without caching some results. 
```{r}
mml_local_str = function(data, vars, arities, sampleSize, targetIndex, logProbTarget,
                                  cachedPXGivenT, probsMtx, str, mbIndices) {
  
  lp = 0
  # a matrix to store the normalizting constant in p(T|Xs)
  margProbs = matrix(1, arities[targetIndex], sampleSize)
  for (curIndex in c(targetIndex, mbIndices)) {# go through each node in a given str
    
    # if it has at least one parent,
    # then get the adaptive count of it given its parent set
    curPa = which(str[, vars[curIndex]] == 1)
    if (length(curPa) > 0) {
      
      curPaIndices = which(vars %in% names(curPa))
      condProbsAdpt = cond_probs_adaptive(data, arities, sampleSize, targetIndex, probsMtx, 
                                          curIndex, curPaIndices)
      lpEachNode = sum(log(t(condProbsAdpt)[cbind(seq_along(data[, targetIndex]), data[, targetIndex])]))
      margProbs = margProbs * condProbsAdpt
      lp = lp + lpEachNode
      
    } else if ((curIndex == targetIndex) && (length(curPa) < 1)) {
      
      lpEachNode = logProbTarget
      margProbs = margProbs * cachedPXGivenT[[targetIndex]]
      lp = lp + lpEachNode
      
    } # end if else
    
  }
  
  nlp = -(lp - sum(log(apply(margProbs, 2, sum)))) # -log(p(T|Xs))
  return(nlp)
  
}
```

```{r}
dag = randDag(10, 2)
# dag = empty.graph(c("A", "T", "S", "L", "E", "B", "X", "D"))
# dag = set.arc(dag, "A", "T")
# dag = set.arc(dag, "T", "E")
# dag = set.arc(dag, "S", "L")
# dag = set.arc(dag, "S", "B")
# dag = set.arc(dag, "B", "D")
# dag = set.arc(dag, "L", "E")
# dag = set.arc(dag, "E", "X")
# dag = set.arc(dag, "E", "D")
cpts = randCPTs(dag, 2, 1)
n = sampleSize = 1000
smpl = randData(cpts, n)
varCnt = count_occurance(smpl$data, smpl$arities)
data = data.matrix(smpl$data)
arities = smpl$arities
vars = smpl$vars
nvars = length(vars)
mbt = lapply(vars, bnlearn::mb, x = dag)
graphviz.plot(dag)
```

```{r}
no_cores = 4
registerDoParallel(no_cores)
mbcpt = foreach(target = vars,
    .combine = list,
    .multicombine = TRUE) %dopar% {
  forward_greedy_fast(smpl$data, varCnt, arities, vars, n, target)
    }
stopImplicitCluster()
mbcpt = symmetry_correction(vars, mbcpt, "AND")
names(mbcpt) = vars

errors = rep(0, nvars)
for (i in 1:nvars) errors[i] = mb_false_finding(mbt[[i]], mbcpt[[i]])
errors
```

## MH-algorithm
go through the entire space w/o mutations, assuming uniform str prior
```{r}
metropolis_hasting = function(data, vars, arities, sampleSize, targetIndex, logProbTarget, cachedPXGivenT, probsMtx, mbIndices, strList, nItrs) {
  
  nVisits = rep(0L, length(strList))
  indCurrent = sample(length(strList), 1)
  strCurrent = strList[[indCurrent]]
  ICurrent = mml_local_str(data, vars, arities, n, targetIndex, logProbTarget, cachedPXGivenT, probsMtx,
                strCurrent, mbIndices)
  for (itr in 1:nItrs) {
    indNext = sample((1:length(strList))[-indCurrent], 1)
    strNext = strList[[indNext]]
    INext = mml_local_str(data, vars, arities, n, targetIndex, logProbTarget, cachedPXGivenT, probsMtx,
                  strNext, mbIndices)
    # comparing the current and next msg len 
    r = ICurrent - INext
    acceptRate = min(c(r, 0))
    u = log(runif(1))
    #cat("r:", r, "-- rate:", acceptRate, "-- u:", u, "\n")
    if (u < acceptRate) {
      # accept
      indCurrent = indNext
      ICurrent = INext
      nVisits[indCurrent] = nVisits[indCurrent] + 1
    } else {
      nVisits[indCurrent] = nVisits[indCurrent] + 1
    }
  }
  return(nVisits)
  
}
```

apply mh to all nodes having at least 1 parent
```{r}
no_cores = 4
registerDoParallel(no_cores)
posteriorList = foreach(target = vars,
    .combine = list,
    .multicombine = TRUE) %dopar% {
      targetIndex = which(vars == target)  
      mbl = mbcpt[[targetIndex]]
      mbIndices = which(vars %in% mbl)
      if (length(mbl) > 0) {
        strList = readRDS(paste0("~/Documents/PhDProjects/RStudioProjects/local2global/MBPTs_ordered/", length(mbIndices), ".rds"))
        ii = 1
        for (s in strList) {
          dimnames(s) = rep(list(vars[c(mbIndices, targetIndex)]), 2) 
          strList[[ii]] = s
          ii = ii + 1
        }
        probsMtx = matrix(0.5, arities[targetIndex], sampleSize)
        cachedPXGivenT = list() # empty list to cach condProbsAdpt calculated by mml_fixed_str_adaptive()
        for (i in 1:nvars) {
          if (i == targetIndex) {
            cachedPXGivenT[[i]] = probs_adaptive(data, arities, sampleSize, probsMtx, targetIndex)
          } else {
            cachedPXGivenT[[i]] = cond_probs_adaptive(data, arities, sampleSize, targetIndex, probsMtx, i, targetIndex)
          }
        }
        logProbTarget = sum(log(t(cachedPXGivenT[[targetIndex]])[cbind(seq_along(data[, targetIndex]), 
                                                                       data[, targetIndex])]))
        metropolis_hasting(data, vars, arities, sampleSize, targetIndex, logProbTarget, cachedPXGivenT, probsMtx, mbIndices, strList, nItrs = 1000)
      } else {
        -targetIndex
      }
    } # end parallel computing
stopImplicitCluster()
posteriorList
```

## Exact posterior
calculating the exact posterior
```{r}
#mmlList = list()
subgraphList = list()

no_cores = 4
registerDoParallel(no_cores)
mmlList = foreach(target = vars,
    .combine = list,
    .multicombine = TRUE) %dopar% {
  targetIndex = which(vars == target)
  I = c()
  mbIndices = which(vars %in% mbcpt[[targetIndex]])
  if (length(mbIndices) > 0) {
    strList = readRDS(paste0("~/Documents/PhDProjects/RStudioProjects/local2global/MBPTs_ordered/", length(mbIndices), ".rds"))
    for (i in 1:length(strList)) {
      str = strList[[i]]
      dimnames(str) = rep(list(vars[c(mbIndices, targetIndex)]), 2) 
      probsMtx = matrix(0.5, arities[targetIndex], sampleSize)
      cachedPXGivenT = list() # empty list to cach condProbsAdpt calculated by mml_fixed_str_adaptive()
      for (i in 1:nvars) {
        if (i == targetIndex) {
          cachedPXGivenT[[i]] = probs_adaptive(data, arities, sampleSize, probsMtx, targetIndex)
        } else {
          cachedPXGivenT[[i]] = cond_probs_adaptive(data, arities, sampleSize, targetIndex, probsMtx, i, targetIndex)
        }
      }
      logProbTarget = sum(log(t(cachedPXGivenT[[targetIndex]])[cbind(seq_along(data[, targetIndex]), 
                                                                     data[, targetIndex])]))
      I = c(I, mml_local_str(data, vars, arities, n, targetIndex, logProbTarget, cachedPXGivenT, probsMtx, str, mbIndices))
    }
    I
  }
    }
stopImplicitCluster()

# assign 0 to empty mb
mmlList[[which(sapply(mmlList, length) == 0)]] = 0

# for (targetIndex in 1:nvars) {
#   I = c()
#   mbIndices = which(vars %in% mbcpt[[targetIndex]])
#   strList = readRDS(paste0("~/Documents/PhDProjects/RStudioProjects/local2global/MBPTs_ordered/", length(mbIndices), ".rds"))
#   for (i in 1:length(strList)) {
#     str = strList[[i]]
#     dimnames(str) = rep(list(vars[c(mbIndices, targetIndex)]), 2) 
#     probsMtx = matrix(0.5, arities[targetIndex], sampleSize)
#     cachedPXGivenT = list() # empty list to cach condProbsAdpt calculated by mml_fixed_str_adaptive()
#     for (i in 1:nvars) {
#       if (i == targetIndex) {
#         cachedPXGivenT[[i]] = probs_adaptive(data, arities, sampleSize, probsMtx, targetIndex)
#       } else {
#         cachedPXGivenT[[i]] = cond_probs_adaptive(data, arities, sampleSize, targetIndex, probsMtx, i, targetIndex)
#       }
#     }
#     logProbTarget = sum(log(t(cachedPXGivenT[[targetIndex]])[cbind(seq_along(data[, targetIndex]), 
#                                                                    data[, targetIndex])]))
#     I = c(I, mml_local_str(data, vars, arities, n, targetIndex, logProbTarget, cachedPXGivenT, probsMtx, str, mbIndices))
#   }
#   mmlList[[targetIndex]] = I
#   
# }

```
## Merging all subgraphs
```{r}
optSubgraphList = list()
optSubgraphInd = sapply(mmlList, which.min)
for (targetIndex in 1:nvars) {
  mbIndices = which(vars %in% mbcpt[[targetIndex]])
  if (length(mbIndices) > 0) {
    strList = readRDS(paste0("~/Documents/PhDProjects/RStudioProjects/local2global/MBPTs_ordered/", length(mbIndices), ".rds"))
    str = strList[[optSubgraphInd[targetIndex]]]
    dimnames(str) = rep(list(vars[c(mbIndices, targetIndex)]), 2)
    optSubgraphList[[targetIndex]] = str
  } else {
    optSubgraphList[[targetIndex]] = 0
  }
}

arcs = function(mtx) {
  e = c()
  for (i in 1:nrow(mtx)) {
    for (j in 1:ncol(mtx)) {
      if (mtx[i, j] == 1) e = c(e, rownames(mtx)[i], colnames(mtx)[j])
    }
  }
  e = matrix(e, ncol = 2, byrow = T)
  colnames(e) = c("from", "to")
  return(e)
}

# global str matrix
globalMtx = matrix(0, nvars, nvars)
dimnames(globalMtx) = rep(list(vars), 2)
blacklist = data.frame(stringsAsFactors = F)
conflictVars = c()
for (targetIndex in 1:nvars) {
  if (length(mbcpt[[targetIndex]]) > 0) {
    str = optSubgraphList[[targetIndex]]
    directedEdges = arcs(str)
    for (i in 1:nrow(directedEdges)) {
      #e = c(directedEdges[i, 1], directedEdges[i, 2])
      from = directedEdges[i, 1]
      to = directedEdges[i, 2]
      e = c(from, to)
      if (is.na(row.match(e, blacklist))) {# if not in blacklist
        if (globalMtx[to, from] == 0) {# if no conflict, update cnt
          globalMtx[from, to] = globalMtx[from, to] + 1  
        } else {# else, remove both directions
          globalMtx[to, from] = 0
          blacklist = rbind(blacklist, e, stringsAsFactors = F)
        }
      }
    }
  }
}

# dealing with conflicts
# find for which target var conflicts occur
for (i in 1:nrow(blacklist)) {
  sumDif = 0 
  e = c(blacklist[i, 1], blacklist[i, 2])
  for (targetIndex in 1:nvars) {
    if (length(mbcpt[[targetIndex]]) > 0) {
      if (prod(e %in% c(vars[targetIndex], mbcpt[[targetIndex]]))) {
        cat(vars[targetIndex], "\n")
        mbIndices = which(vars %in% mbcpt[[targetIndex]])
        strList = readRDS(paste0("~/Documents/PhDProjects/RStudioProjects/local2global/MBPTs_ordered/", length(mbIndices), ".rds"))
      
        str = optSubgraphList[[targetIndex]]
        if (str[e[1], e[2]] == 1) {
          tempStr1 = str
          dimnames(tempStr1) = rep(list(c(paste0("V", 1:length(mbIndices)), "T")), 2)
          l1 = mmlList[[targetIndex]][which(sapply(strList, all.equal, tempStr1) == TRUE)]
        } else if (str[e[2], e[1]] == 1) {
          tempStr2 = str
          dimnames(tempStr2) = rep(list(c(paste0("V", 1:length(mbIndices)), "T")), 2)
          l2 = mmlList[[targetIndex]][which(sapply(strList, all.equal, tempStr2) == TRUE)]
        } else {
          l1 = l2 = 0
        }
        
        deltaMML = l1 - l2 # mml difference b/w two structures 
        cat(deltaMML, "\n")
        sumDif = sumDif + deltaMML
      }
    }
  }
  if (sumDif > 0) {
    globalMtx[e[2], e[1]] = 1
  } else {
    globalMtx[e[1], e[2]] = 1
  }
}

globalMtx = ceiling(globalMtx / max(globalMtx))
is_dag(globalMtx)
```
## hill-climbing dag search 
operations include: arc removal (0.4), reversial (0.4), addition (0.2)
```{r}
dagl = matrix2dag(globalMtx)
for (i in 1:100) {
  if (runif(1) < 0.4) {# arc removal
    ind = sample(1:nrow(dagl$arcs), 1)
    e = dagl$arcs[ind, ]
    from = e[1]
    to = e[2]
    fromInd = which(vars == from)
    toInd = which(vars == to)
    toPa = bnlearn::parents(dagl, to)
    toPaInd = which(vars %in% toPa)
    lbefore = mml_cpt(varCnt, arities, n, toPaInd, toInd, rep(1, arities[toInd]), F)
    lafter = mml_cpt(varCnt, arities, n, toPaInd[toPaInd != fromInd], toInd, rep(1, arities[toInd]), F)
    ldiff = lbefore - lafter
    cat("--remove", e, ":", ldiff, "? \n")
    #if (!ldiff < 0) {# apply operation
    if (abs(ldiff) < 2) {
      dagl = drop.arc(dagl, from, to)
      cat("Yes! \n")
    }
  } else if (runif(1) < 0.7) {# arc reversial 
    ind = sample(1:nrow(dagl$arcs), 1) 
    e = dagl$arcs[ind, ]
    from = e[1]
    to = e[2]
    if (acyclic(reverse.arc(dagl, from, to, check.cycles = F), directed = T)) {# check acyclic
      fromInd = which(vars == from)
      toInd = which(vars == to)
      # for node from
      fromPa = bnlearn::parents(dagl, from)
      fromPaInd = which(vars %in% fromPa)
      lbefore = mml_cpt(varCnt, arities, n, fromPaInd, fromInd, rep(1, arities[fromInd]), F)
      lafter = mml_cpt(varCnt, arities, n, c(fromPaInd, toInd), fromInd, rep(1, arities[fromInd]), F)
      ldiffFrom = lbefore - lafter
      # for node to
      toPa = bnlearn::parents(dagl, to)
      toPaInd = which(vars %in% toPa)
      lbefore = mml_cpt(varCnt, arities, n, toPaInd, toInd, rep(1, arities[toInd]), F)
      lafter = mml_cpt(varCnt, arities, n, toPaInd[toPaInd != fromInd], toInd, rep(1, arities[toInd]), F)
      ldiffTo = lbefore - lafter
      ldiff = ldiffFrom + ldiffTo
      cat("<>reverse", e, ":", ldiff, "? \n")
      #if (!ldiff < 0) {# apply operation
      if (abs(ldiff) < 2) {
        dagl = reverse.arc(dagl, from, to)
        cat("Yes! \n")
      }
    }
  } else {# arc addition
    var = sample(vars, 1)
    varInd = which(vars == var)
    toAdd = sample(vars[-varInd], 1)
    toAddInd = which(vars == toAdd)
    if (acyclic(set.arc(dagl, toAdd, var, check.cycles = F))) {
      pa = bnlearn::parents(dagl, var)
      paInd = which(vars %in% pa)
      lbefore = mml_cpt(varCnt, arities, n, paInd, varInd, rep(1, arities[varInd]), F)
      lafter = mml_cpt(varCnt, arities, n, c(paInd, toAddInd), varInd, rep(1, arities[varInd]), F)
      ldiff = lbefore - lafter
      cat("++addition", e, ":", ldiff, "? \n")
      #if (!ldiff < 0) {# apply operation
      if (abs(ldiff) < 2) {
        dagl = set.arc(dagl, toAdd, var)
        cat("Yes! \n")
      }
    }
  }
}


```


```{r}
editDistDags(matrix2dag(globalMtx), dag)
editDistDags(dagl, dag, debug = T)
editDistDags(mmhc(smpl$data), dag)
#graphviz.plot(matrix2dag(globalMtx))
```

```{r}
# this function check if a given graph is a dag
# the input is based on graph adjacency matrix
# mtx %^% n is the power of a mtrix, this requires the library expm
is_dag = function(mtx) {
  
  eligible = TRUE
  
  for (n in 1:ncol(mtx)) {
    
    if (sum(diag(mtx %^% n)) > 0) {
      
      eligible = FALSE
      break
      
    } # end if 
    
  } # end for n
  
  return(eligible)
  
}

is_dag2 = function(x) {
  
  if (!is.matrix(x)) {
    
    lnodes = bnlearn::nodes(x)
    lpars = list()
    for (i in 1:length(lnodes)) {
      
      lpars[[i]] = x$nodes[[i]]$parents  
      
    }
    
  } else {
    
    lnodes = colnames(x)
    lpars = list()
    for (i in 1:length(lnodes)) {
      
      lpars[[i]] = which(x[, i] == 1)
      
    }  
    
  } # end else 
  
  return(isDAG(lnodes, lpars))
  
}

# check if arcs x and y are same, reversed, or different
# this function is called by editDistDags/hammingDags
checkArc = function(x, y) {
  
  if (prod(x == y)) {# when x and y are identical
    
    allEqual = 1
    
  } else if (prod(x == rev(y))) {# when x and y are in a reverse order
    
    allEqual = -1
    
  } else {# when x and y are not equal
    
    allEqual = 0
    
  }
  
  return(allEqual)
  
}

# edit distance between dags
# this is the same function as the hammingDags function used in autoEditDistance in bn evaluations
editDistDags = function(learned, true, debug = FALSE) {
  
  arcsLearned = directed.arcs(learned) 
  
  arcsTrue = directed.arcs(true)
  
  addition = 0
  deletion = 0
  reversion = 0
  
  # checkTrue = 0 means arc in true not in learned
  # hence addition add 1
  # checkTrue = -1 means arc in both but wrong direction
  # hence reversion add 1
  
  if ((nrow(arcsTrue) == 0) && (nrow(arcsLearned) > 0)) {
    
    # if dagTrue is empty but not dagLearned 
    deletion = nrow(arcsLearned)
    if (debug) cat("All arcs in the learned dag need to be deleted. \n")
    
  } else if ((nrow(arcsTrue) > 0) && (nrow(arcsLearned) == 0)) {
    
    # if dagLearned is empty but not dagTrue
    addition = nrow(arcsTrue)
    if (debug) cat("All arcs in the true dag need to be added to the learned dag. \n")
    
  } else if ((nrow(arcsTrue) > 0) && (nrow(arcsLearned) > 0)) {
    
    # if both dags are not empty
    for (i in 1:nrow(arcsTrue)) {
      
      # check if each arc in true appears in learned with the correct or reversed direction
      # as there can be only one 1 or -1, then sum up all results
      checkTrue = sum(apply(arcsLearned, 1, checkArc, x = arcsTrue[i,]))
      
      if (checkTrue == 0) {
        
        addition = addition + 1
        if (debug) {
          
          cat("* arcs between", arcsTrue[i,][[1]], "and", arcsTrue[i,][[2]], "do not match (addition). \n")
          cat("  > the learned network contains no arc between", arcsTrue[i,][[1]], "and", arcsTrue[i,][[2]], ". \n")
          cat("  > the true network contains", arcsTrue[i,][[1]], "->", arcsTrue[i,][[2]], ". \n")
          
        } # end debug
        
      } else if (checkTrue == -1) {
        
        reversion = reversion + 1
        if (debug) {
          
          cat("* arcs between", arcsTrue[i,][[1]], "and", arcsTrue[i,][[2]], "do not match (reversion). \n")
          cat("  > the learned network contains", arcsTrue[i,][[2]], "->", arcsTrue[i,][[1]], ". \n")
          cat("  > the true network contains", arcsTrue[i,][[1]], "->", arcsTrue[i,][[2]], ". \n")
          
        } # end debug
        
      } # end else if
      
    } # end for i
    
    for (j in 1:nrow(arcsLearned)) {
      
      # check if each arc in learned appears in true
      # as there can be only one 1 or -1, sum up all results
      checkLearned = sum(apply(arcsTrue, 1, checkArc, x = arcsLearned[j,]))
      
      if (checkLearned == 0) {
        
        deletion = deletion + 1
        if (debug) {
          
          cat("* arcs between", arcsLearned[j,][[1]], "and", arcsLearned[j,][[2]], "do not match (deletion). \n")
          cat("  > the learned network contains", arcsLearned[j,][[1]], "->", arcsLearned[j,][[2]], ". \n")
          cat("  > the true network contains no arc between", arcsLearned[j,][[1]], "and", arcsLearned[j,][[2]], ". \n")
          
        } # end debug
      
      } # end if 
      
    } # end for j
    
  }
  
  return(sum(addition, deletion, reversion))
  
}
```





